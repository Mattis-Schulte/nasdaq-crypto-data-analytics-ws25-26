{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aufgabe 1\n",
    "### Data Preprocessing"
   ],
   "id": "6dc82288ba00fe2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import Libraries",
   "id": "9e6ecac62ae57369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T11:42:13.490690100Z",
     "start_time": "2026-01-09T11:42:08.991463300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ],
   "id": "ce413b089e3bd705",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define Constants",
   "id": "87067263f8e79bb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T11:42:14.553116700Z",
     "start_time": "2026-01-09T11:42:14.527507400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = Path(\"..\", \"data\")\n",
    "RAW, OUT = DATA_DIR / \"raw\", DATA_DIR / \"processed\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "START = pd.Timestamp(\"2000-01-01\")\n",
    "END = pd.Timestamp(\"2025-12-31\")\n",
    "EFFECTIVE_END = min(END, pd.Timestamp.today().normalize())\n",
    "TOL = 0.05  # split confirmation tolerance"
   ],
   "id": "f3d1e7e8899e9f82",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define Functions",
   "id": "ac55c67e5ccac457"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:37:35.855973300Z",
     "start_time": "2026-01-09T12:37:35.806792600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_date(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converts a Series to Datetime and remove timezone information\"\"\"\n",
    "    return pd.to_datetime(s, errors=\"coerce\").dt.tz_localize(None)\n",
    "\n",
    "\n",
    "def clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Strips and lowers the column labels of a Dataframe\"\"\"\n",
    "    df.columns = df.columns.map(lambda label: label.strip().lower())\n",
    "    return df\n",
    "\n",
    "\n",
    "def batch(seq, size: int):\n",
    "    for i in range(0, len(seq), size):\n",
    "        yield seq[i : i + size]\n",
    "\n",
    "\n",
    "def quality(df: pd.DataFrame, name: str) -> None:\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"rows:\", len(df), \"| tickers:\", df[\"ticker\"].nunique() if \"ticker\" in df else \"n/a\")\n",
    "    if \"date\" in df:\n",
    "        print(\"range:\", df[\"date\"].min(), \"->\", df[\"date\"].max())\n",
    "    if {\"open\", \"close\"}.issubset(df.columns):\n",
    "        print(\"missing open:\", df[\"open\"].isna().mean(), \"| missing close:\", df[\"close\"].isna().mean())\n",
    "    if {\"ticker\", \"date\"}.issubset(df.columns):\n",
    "        print(\"dup(ticker,date):\", df.duplicated([\"ticker\", \"date\"]).sum())\n",
    "\n",
    "\n",
    "def load_price_dir(dirpath: Path) -> pd.DataFrame:\n",
    "    \"\"\"Merge all CSV Files of a directory into one Dataframe\\n\n",
    "    Covert date column to dates and open/close column to ints\"\"\"\n",
    "\n",
    "    frames = []\n",
    "    for f in sorted(dirpath.glob(\"*.csv\")):\n",
    "        d = clean_cols(pd.read_csv(f))\n",
    "        # d[\"ticker\"] = d[\"ticker\"].map(norm_ticker)\n",
    "        d[\"date\"] = to_date(d[\"date\"])\n",
    "\n",
    "        for c in (\"open\", \"close\"):\n",
    "            d[c] = pd.to_numeric(d[c], errors=\"coerce\")\n",
    "\n",
    "\n",
    "        d = d.loc[(d[\"date\"] >= START) & (d[\"date\"] <= END), [\"ticker\", \"date\", \"open\", \"close\"]]\n",
    "\n",
    "        frames.append(d)\n",
    "\n",
    "    return pd.concat(frames, ignore_index=True)"
   ],
   "id": "fc9243b7a8f985ed",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get Meta information (screener + addresses) and merge them",
   "id": "f087fa1d20b833"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T01:21:03.020998700Z",
     "start_time": "2026-01-09T01:21:02.856600900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "meta_file = RAW / \"nasdaq_screener.csv\"\n",
    "addr_file = RAW / \"nasdaq_company_addresses.csv\"\n",
    "\n",
    "# Meta has two tickers called NA and NAN. These are converted to NaN. To prevent this keep_default_na is False\n",
    "meta = clean_cols(pd.read_csv(meta_file, keep_default_na=False)).rename(columns={\"symbol\": \"ticker\"})\n",
    "# meta has no ticker duplicates\n",
    "\n",
    "addr = clean_cols(pd.read_csv(addr_file))\n",
    "# addr has no ticker duplicates\n",
    "\n",
    "print(f\"{addr.shape[0]} of {meta.shape[0]} tickers have an address\\n\")\n",
    "\n",
    "df_nasdaq_meta = meta.merge(addr, on=\"ticker\", how=\"left\")\n",
    "df_nasdaq_meta.head(5)\n"
   ],
   "id": "d9bcfeaa13dfe1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3308 of 7023 tickers have an address\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  ticker                                               name last sale  \\\n",
       "0      A             Agilent Technologies Inc. Common Stock   $146.59   \n",
       "1     AA                    Alcoa Corporation Common Stock     $39.90   \n",
       "2   AACB  Artius II Acquisition Inc. Class A Ordinary Sh...    $10.24   \n",
       "3  AACBR                  Artius II Acquisition Inc. Rights     $0.34   \n",
       "4  AACBU                   Artius II Acquisition Inc. Units    $10.70   \n",
       "\n",
       "   net change % change      market cap        country ipo year   volume  \\\n",
       "0       -1.44  -0.973%  41558327594.00  United States     1999  1187952   \n",
       "1        0.48   1.218%  10330697448.00  United States     2016  7207004   \n",
       "2       -0.01  -0.098%            0.00  United States     2025    10915   \n",
       "3        0.02    6.25%            0.00  United States     2025   379367   \n",
       "4        0.00    0.00%            0.00  United States     2025     1102   \n",
       "\n",
       "        sector                                          industry address  \n",
       "0  Industrials  Biotechnology: Laboratory Analytical Instruments     NaN  \n",
       "1  Industrials                                          Aluminum     NaN  \n",
       "2                                                                    NaN  \n",
       "3                                                                    NaN  \n",
       "4      Finance                                      Blank Checks     NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>last sale</th>\n",
       "      <th>net change</th>\n",
       "      <th>% change</th>\n",
       "      <th>market cap</th>\n",
       "      <th>country</th>\n",
       "      <th>ipo year</th>\n",
       "      <th>volume</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies Inc. Common Stock</td>\n",
       "      <td>$146.59</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-0.973%</td>\n",
       "      <td>41558327594.00</td>\n",
       "      <td>United States</td>\n",
       "      <td>1999</td>\n",
       "      <td>1187952</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Biotechnology: Laboratory Analytical Instruments</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation Common Stock</td>\n",
       "      <td>$39.90</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.218%</td>\n",
       "      <td>10330697448.00</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>7207004</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Aluminum</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AACB</td>\n",
       "      <td>Artius II Acquisition Inc. Class A Ordinary Sh...</td>\n",
       "      <td>$10.24</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.098%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>United States</td>\n",
       "      <td>2025</td>\n",
       "      <td>10915</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACBR</td>\n",
       "      <td>Artius II Acquisition Inc. Rights</td>\n",
       "      <td>$0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.25%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>United States</td>\n",
       "      <td>2025</td>\n",
       "      <td>379367</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACBU</td>\n",
       "      <td>Artius II Acquisition Inc. Units</td>\n",
       "      <td>$10.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00</td>\n",
       "      <td>United States</td>\n",
       "      <td>2025</td>\n",
       "      <td>1102</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Blank Checks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NASDAQ & Undoing Splits",
   "id": "5436f9ca2f2cb32f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T14:19:31.210385300Z",
     "start_time": "2026-01-09T14:19:08.598083700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nasdaq_path = RAW / \"nasdaq-daily\"\n",
    "splits_path = RAW / \"splits_2000_2025.csv\"\n",
    "\n",
    "nasdaq = load_price_dir(nasdaq_path)\n",
    "\n",
    "splits = clean_cols(pd.read_csv(splits_path))\n",
    "splits = splits.rename(\n",
    "    columns={\n",
    "        \"symbol\": \"ticker\",\n",
    "        \"stock splits\": \"split_factor\",\n",
    "    }\n",
    ")\n",
    "splits = splits[[\"ticker\", \"date\", \"split_factor\"]]\n",
    "splits[\"date\"] = to_date(splits[\"date\"])\n",
    "splits[\"split_factor\"] = pd.to_numeric(splits[\"split_factor\"], errors=\"coerce\")\n",
    "splits = splits[(splits[\"date\"] >= START) & (splits[\"date\"] <= END)]\n",
    "\n",
    "# nasdaq, n_adj = adjust_splits_if_needed(nasdaq, splits, tol=TOL)\n",
    "\n",
    "def undo_split(row:pd.Series) -> None:\n",
    "    nasdaq.loc[(nasdaq[\"ticker\"] == row[1]) & (nasdaq[\"date\"] >= row[2])][\"open\"] *= row[3]\n",
    "    nasdaq.loc[(nasdaq[\"ticker\"] == row[1]) & (nasdaq[\"date\"] >= row[2])][\"close\"] *= row[3]\n",
    "    print(\"done\")\n",
    "\n",
    "# TODO Viel zu langsam. Script Version scheint schneller zu sein\n",
    "for i in splits.itertuples():\n",
    "    undo_split(i)\n",
    "# splits.apply(undo_split, axis=1)\n",
    "# quality(nasdaq, \"NASDAQ daily (after split-check, before yfinance)\")\n",
    "\"\"\"\n",
    "need = tickers_needing_yf(nasdaq, EFFECTIVE_END)\n",
    "yf_n = yf_fetch_batched(need, START, EFFECTIVE_END)\n",
    "df_nasdaq_daily = merge_prices_with_yf(nasdaq, yf_n)[[\"ticker\", \"date\", \"open\", \"close\"]]\n",
    "df_nasdaq_weekly = daily_to_weekly(df_nasdaq_daily)\"\"\"\n",
    "nasdaq"
   ],
   "id": "1891d13e5046d1c5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthias\\AppData\\Local\\Temp\\ipykernel_15704\\2638508347.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nasdaq.loc[(nasdaq[\"ticker\"] == row[1]) & (nasdaq[\"date\"] >= row[2])][\"open\"] *= row[3]\n",
      "C:\\Users\\Matthias\\AppData\\Local\\Temp\\ipykernel_15704\\2638508347.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nasdaq.loc[(nasdaq[\"ticker\"] == row[1]) & (nasdaq[\"date\"] >= row[2])][\"close\"] *= row[3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[69]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     18\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mdone\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m splits.itertuples():\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m     \u001B[43mundo_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# splits.apply(undo_split, axis=1)\u001B[39;00m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# quality(nasdaq, \"NASDAQ daily (after split-check, before yfinance)\")\u001B[39;00m\n\u001B[32m     24\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     25\u001B[39m \u001B[33;03mneed = tickers_needing_yf(nasdaq, EFFECTIVE_END)\u001B[39;00m\n\u001B[32m     26\u001B[39m \u001B[33;03myf_n = yf_fetch_batched(need, START, EFFECTIVE_END)\u001B[39;00m\n\u001B[32m     27\u001B[39m \u001B[33;03mdf_nasdaq_daily = merge_prices_with_yf(nasdaq, yf_n)[[\"ticker\", \"date\", \"open\", \"close\"]]\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[33;03mdf_nasdaq_weekly = daily_to_weekly(df_nasdaq_daily)\"\"\"\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[69]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mundo_split\u001B[39m\u001B[34m(row)\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mundo_split\u001B[39m(row:pd.Series) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     16\u001B[39m     nasdaq.loc[(nasdaq[\u001B[33m\"\u001B[39m\u001B[33mticker\u001B[39m\u001B[33m\"\u001B[39m] == row[\u001B[32m1\u001B[39m]) & (nasdaq[\u001B[33m\"\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m\"\u001B[39m] >= row[\u001B[32m2\u001B[39m])][\u001B[33m\"\u001B[39m\u001B[33mopen\u001B[39m\u001B[33m\"\u001B[39m] *= row[\u001B[32m3\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     nasdaq.loc[(\u001B[43mnasdaq\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mticker\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m) & (nasdaq[\u001B[33m\"\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m\"\u001B[39m] >= row[\u001B[32m2\u001B[39m])][\u001B[33m\"\u001B[39m\u001B[33mclose\u001B[39m\u001B[33m\"\u001B[39m] *= row[\u001B[32m3\u001B[39m]\n\u001B[32m     18\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mdone\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001B[39m, in \u001B[36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[39m\u001B[34m(self, other)\u001B[39m\n\u001B[32m     72\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[32m     74\u001B[39m other = item_from_zerodim(other)\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001B[39m, in \u001B[36mOpsMixin.__eq__\u001B[39m\u001B[34m(self, other)\u001B[39m\n\u001B[32m     38\u001B[39m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m__eq__\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__eq__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_cmp_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[43m.\u001B[49m\u001B[43meq\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\series.py:6138\u001B[39m, in \u001B[36mSeries._cmp_method\u001B[39m\u001B[34m(self, other, op)\u001B[39m\n\u001B[32m   6135\u001B[39m lvalues = \u001B[38;5;28mself\u001B[39m._values\n\u001B[32m   6136\u001B[39m rvalues = extract_array(other, extract_numpy=\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m6138\u001B[39m res_values = \u001B[43mops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcomparison_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   6140\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._construct_result(res_values, name=res_name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001B[39m, in \u001B[36mcomparison_op\u001B[39m\u001B[34m(left, right, op)\u001B[39m\n\u001B[32m    341\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m lvalues.dtype == \u001B[38;5;28mobject\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rvalues, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m344\u001B[39m     res_values = \u001B[43mcomp_method_OBJECT_ARRAY\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    346\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    347\u001B[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:129\u001B[39m, in \u001B[36mcomp_method_OBJECT_ARRAY\u001B[39m\u001B[34m(op, x, y)\u001B[39m\n\u001B[32m    127\u001B[39m     result = libops.vec_compare(x.ravel(), y.ravel(), op)\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     result = \u001B[43mlibops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscalar_compare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result.reshape(x.shape)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

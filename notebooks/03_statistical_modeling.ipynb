{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf1c85b6",
      "metadata": {},
      "source": [
        "# Model building (Linear Regression)\n",
        "\n",
        "This notebook trains a scikit-learn Linear Regression model to predict next-day close (t+1) for NVIDIA (NVDA) using the cleaned NASDAQ dataset from the pipeline.\n",
        "\n",
        "## What this notebook does\n",
        "1) Load the cleaned daily NASDAQ dataset (`df_nasdaq_daily.csv`)\n",
        "2) Filter to NVDA and the date window 2015–2025\n",
        "3) Build time-series features (lags + simple technical stats)\n",
        "4) Split by time (no shuffling):\n",
        "   - Train: 2015–2023\n",
        "   - Validation: 2024 (feature-engineering selection)\n",
        "   - Test: 2025 (final evaluation)\n",
        "5) Train a final model and evaluate it with MAPE\n",
        "6) Produce two forecasting modes for 2026-02-02:\n",
        "   - **(a) Ex-post** (best case): uses real history up to the last trading day before the target (via yfinance extension)\n",
        "   - **(b) Autoregressive** (realistic): only uses info available at 2026-01-18, then feeds predictions back in\n",
        "\n",
        "## Outputs / checks\n",
        "- **Validation selection**: choose the lookback window with lowest 2024 MAPE\n",
        "- **Test evaluation** (unseen 2025): report MAPE, plot true vs predicted\n",
        "- **Model form**: show the linear regression functional form\n",
        "- **Forward forecast**: compare predicted vs true close on 2026-02-02 and discuss limitations\n",
        "\n",
        "## Data\n",
        "Input file: `../data/processed/df_nasdaq_daily.csv` with columns:\n",
        "- `ticker`, `date`, `close`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "config",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config\n",
        "DATA_DIR = Path(\"../data\")\n",
        "NASDAQ_DAILY_FILE = DATA_DIR / \"processed\" / \"df_nasdaq_daily.csv\"\n",
        "\n",
        "TICKER = \"NVDA\"\n",
        "\n",
        "START = pd.Timestamp(\"2015-01-01\")\n",
        "TRAIN_END = pd.Timestamp(\"2023-12-31\")\n",
        "VAL_END = pd.Timestamp(\"2024-12-31\")\n",
        "TEST_END = pd.Timestamp(\"2025-12-31\")\n",
        "\n",
        "# feature engineering search space (validated on 2024)\n",
        "CANDIDATE_LOOKBACKS = [5, 10, 20, 30]\n",
        "\n",
        "TARGET_DAY = pd.Timestamp(\"2026-02-02\")\n",
        "CUTOFF_DAY = pd.Timestamp(\"2026-01-18\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load NVDA (processed NASDAQ daily)\n",
        "df = pd.read_csv(NASDAQ_DAILY_FILE, keep_default_na=False)\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.tz_localize(None)\n",
        "df[\"ticker\"] = df[\"ticker\"].astype(str).str.strip()\n",
        "df[\"close\"] = pd.to_numeric(df[\"close\"], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna(subset=[\"date\", \"ticker\", \"close\"])\n",
        "df = df[(df[\"ticker\"] == TICKER) & (df[\"date\"].between(START, TEST_END))]\n",
        "df = df.sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "features_helpers",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_features_next_close(df_prices: pd.DataFrame, lookback: int) -> tuple[pd.DataFrame, list[str]]:\n",
        "    \"\"\"Build features at day t to predict close(t+1), using only close-based features.\"\"\"\n",
        "    x = df_prices.sort_values(\"date\").reset_index(drop=True).copy()\n",
        "\n",
        "    # Target: next day's close\n",
        "    x[\"target_date\"] = x[\"date\"].shift(-1)\n",
        "    x[\"y\"] = x[\"close\"].shift(-1)\n",
        "\n",
        "    # Close lags: c0=close_t, c1=close_{t-1}, ...\n",
        "    for i in range(lookback):\n",
        "        x[f\"c{i}\"] = x[\"close\"].shift(i)\n",
        "\n",
        "    # Derived features (end at t)\n",
        "    x[\"ret_1\"] = x[\"close\"].pct_change(1, fill_method=None)\n",
        "    x[\"ret_5\"] = x[\"close\"].pct_change(5, fill_method=None)\n",
        "    x[\"ma_3\"] = x[\"close\"].rolling(3).mean()\n",
        "    x[\"ma_L\"] = x[\"close\"].rolling(lookback).mean()\n",
        "    x[\"std_L\"] = x[\"close\"].rolling(lookback).std()\n",
        "\n",
        "    feat_cols = [f\"c{i}\" for i in range(lookback)] + [\"ret_1\", \"ret_5\", \"ma_3\", \"ma_L\", \"std_L\"]\n",
        "    out = x[[\"date\", \"target_date\", \"y\"] + feat_cols].dropna().reset_index(drop=True)\n",
        "    return out, feat_cols\n",
        "\n",
        "\n",
        "def split_by_target_date(d: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    train = d[d[\"target_date\"].between(START, TRAIN_END)].copy()\n",
        "    val = d[d[\"target_date\"].between(TRAIN_END + pd.Timedelta(days=1), VAL_END)].copy()\n",
        "    test = d[d[\"target_date\"].between(VAL_END + pd.Timedelta(days=1), TEST_END)].copy()\n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54dc80d9",
      "metadata": {},
      "source": [
        "## Feature engineering (validated on 2024)\n",
        "\n",
        "We create a small family of feature sets by varying the lookback window.\n",
        "The best lookback is chosen based on the lowest MAPE on the 2024 validation split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "select_lookback",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_L = None\n",
        "best_mape_val = np.inf\n",
        "\n",
        "for L in CANDIDATE_LOOKBACKS:\n",
        "    d, feat_cols = make_features_next_close(df, lookback=L)\n",
        "    train, val, _ = split_by_target_date(d)\n",
        "\n",
        "    model = LinearRegression().fit(train[feat_cols], train[\"y\"])\n",
        "    val_pred = model.predict(val[feat_cols])\n",
        "    mape = mean_absolute_percentage_error(val[\"y\"], val_pred)\n",
        "\n",
        "    if mape < best_mape_val:\n",
        "        best_mape_val = mape\n",
        "        best_L = L\n",
        "\n",
        "best_L, best_mape_val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b6ef61",
      "metadata": {},
      "source": [
        "## Evaluation step 1: test performance (2025)\n",
        "\n",
        "We train the final linear regression model on train + validation (2015–2024) and evaluate it on the unseen test set (2025).\n",
        "\n",
        "Metric: Mean Absolute Percentage Error (MAPE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train_eval_test",
      "metadata": {},
      "outputs": [],
      "source": [
        "d, feat_cols = make_features_next_close(df, lookback=best_L)\n",
        "train, val, test = split_by_target_date(d)\n",
        "\n",
        "train_val = pd.concat([train, val], ignore_index=True)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(train_val[feat_cols].to_numpy(), train_val[\"y\"].to_numpy())\n",
        "\n",
        "y_test = test[\"y\"].to_numpy()\n",
        "y_test_pred = model.predict(test[feat_cols].to_numpy())\n",
        "mape_test = mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "\n",
        "print(\"Selected lookback:\", best_L)\n",
        "print(\"Test MAPE (2025):\", mape_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967d9119",
      "metadata": {},
      "source": [
        "### Test set visualization\n",
        "Predicted vs true close prices for the 2025 test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot_test",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_df = pd.DataFrame(\n",
        "    {\n",
        "        \"date\": test[\"target_date\"],\n",
        "        \"true_close\": y_test,\n",
        "        \"pred_close\": y_test_pred,\n",
        "    }\n",
        ")\n",
        "\n",
        "fig = px.line(\n",
        "    plot_df,\n",
        "    x=\"date\",\n",
        "    y=[\"true_close\", \"pred_close\"],\n",
        "    title=f\"{TICKER} — Test set (2025): true vs predicted close\",\n",
        "    labels={\"value\": \"close\", \"variable\": \"\", \"date\": \"date\"},\n",
        ")\n",
        "fig.update_layout(legend_title_text=\"\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52cc147d",
      "metadata": {},
      "source": [
        "### Functional form of linear regression\n",
        "\n",
        "Linear regression models a linear relationship between the feature vector $x$ and the prediction $\\hat{y}$:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\beta_0 + \\sum_{i=1}^{p} \\beta_i x_i\n",
        "$$\n",
        "\n",
        "where $\\beta_0$ is the intercept and $\\beta_i$ are the learned coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "print_form",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"y_hat = intercept + Σ coef_i * x_i\")\n",
        "print(\"intercept:\", model.intercept_)\n",
        "print(\"n_features:\", len(feat_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yf_and_final_model",
      "metadata": {},
      "outputs": [],
      "source": [
        "def yf_nvda_daily(start: str, end: str) -> pd.DataFrame:\n",
        "    data = yf.download(\n",
        "        TICKER,\n",
        "        start=start,\n",
        "        end=(pd.Timestamp(end) + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
        "        auto_adjust=True,\n",
        "        progress=False,\n",
        "        threads=False,\n",
        "        group_by=\"column\",\n",
        "        actions=False,\n",
        "    )\n",
        "\n",
        "    if data is None or data.empty:\n",
        "        return pd.DataFrame(columns=[\"date\", \"close\"])\n",
        "\n",
        "    data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "    data = data.reset_index().rename(columns={\"Date\": \"date\", \"Close\": \"close\"})\n",
        "    data[\"date\"] = pd.to_datetime(data[\"date\"]).dt.tz_localize(None)\n",
        "    data[\"close\"] = pd.to_numeric(data[\"close\"], errors=\"coerce\")\n",
        "\n",
        "    return data[[\"date\", \"close\"]].dropna().sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "# Train a final model on the full 2015–2025 history (for the step-2 forecasts)\n",
        "d_all, feat_cols_all = make_features_next_close(df, lookback=best_L)\n",
        "train_all = d_all[d_all[\"target_date\"].between(START, TEST_END)].copy()\n",
        "\n",
        "model_all = LinearRegression()\n",
        "model_all.fit(train_all[feat_cols_all].to_numpy(), train_all[\"y\"].to_numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8422a556",
      "metadata": {},
      "source": [
        "## Evaluation step 2(a): ex-post prediction\n",
        "\n",
        "We predict the close on 2026-02-02 using the real price history up to the last trading day before that date.\n",
        "\n",
        "To ensure we have the required history after 2025-12-31, we fill the missing period 2026-01-01 ... 2026-02-02 via yfinance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "expost",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extend history using yfinance\n",
        "yf_ext = yf_nvda_daily((pd.Timestamp(TEST_END) + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"), TARGET_DAY)\n",
        "\n",
        "df_hist = df.loc[df[\"date\"].between(START, TEST_END), [\"date\", \"close\"]].copy()\n",
        "df_combo = pd.concat([df_hist, yf_ext.loc[yf_ext[\"date\"] > TEST_END]], ignore_index=True)\n",
        "df_combo = df_combo.drop_duplicates(\"date\").sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "# Build features + select evaluation day (fallback if target not available)\n",
        "d_combo, feat_cols_combo = make_features_next_close(df_combo, lookback=best_L)\n",
        "eval_day = TARGET_DAY if (df_combo[\"date\"] == TARGET_DAY).any() else df_combo.loc[df_combo[\"date\"] <= TARGET_DAY, \"date\"].max()\n",
        "\n",
        "row = d_combo.loc[d_combo[\"target_date\"] == eval_day]\n",
        "pred_expost = float(model_all.predict(row[feat_cols_combo].to_numpy())[0])\n",
        "\n",
        "true_close = float(yf_ext.loc[yf_ext[\"date\"] == eval_day, \"close\"].iloc[0])\n",
        "rel_err = abs(pred_expost - true_close) / true_close\n",
        "\n",
        "print(\"Ex-post prediction\")\n",
        "print(\"requested:\", TARGET_DAY.date(), \"| used:\", eval_day.date())\n",
        "print(\"pred:\", pred_expost, \"| true:\", true_close, \"| rel_err:\", float(rel_err))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4722df2",
      "metadata": {},
      "source": [
        "## Evaluation step 2(b): autoregressive forward forecast\n",
        "\n",
        "We predict the close on 2026-02-02 using only information available at 2026-01-18.\n",
        "\n",
        "From the cutoff date onward, each next-day close is predicted and then fed back into the feature history.\n",
        "This simulates a real-world setting where future closes are unknown, which leads to error propagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "autoregressive_helpers",
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_vector_from_closes(closes: np.ndarray, lookback: int) -> np.ndarray:\n",
        "    \"\"\"Build one feature vector to predict next close given close history up to time t.\"\"\"\n",
        "    c = closes[::-1]  # newest first\n",
        "\n",
        "    feats = list(c[:lookback])\n",
        "    ret_1 = c[0] / c[1] - 1.0\n",
        "    ret_5 = c[0] / c[5] - 1.0\n",
        "    ma_3 = float(np.mean(c[:3]))\n",
        "    ma_L = float(np.mean(c[:lookback]))\n",
        "    std_L = float(np.std(c[:lookback], ddof=1))\n",
        "\n",
        "    feats.extend([ret_1, ret_5, ma_3, ma_L, std_L])\n",
        "    return np.array(feats, dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "autoregressive",
      "metadata": {},
      "outputs": [],
      "source": [
        "CUTOFF_DAY =  pd.Timestamp(\"2025-12-01\")\n",
        "TARGET_DAY = pd.Timestamp(\"2026-01-16\")\n",
        "\n",
        "last_known = df_combo.loc[df_combo[\"date\"] <= CUTOFF_DAY, \"date\"].max()\n",
        "future_dates = df_combo.loc[(df_combo[\"date\"] > last_known) & (df_combo[\"date\"] <= TARGET_DAY), \"date\"].tolist()\n",
        "known_closes = df_combo.loc[df_combo[\"date\"] <= last_known, \"close\"].to_numpy().astype(float)\n",
        "\n",
        "pred_rows = []\n",
        "for dt in future_dates:\n",
        "    x_vec = feature_vector_from_closes(known_closes, lookback=best_L)\n",
        "    y_pred = float(model_all.predict(x_vec.reshape(1, -1))[0])\n",
        "    pred_rows.append({\"date\": dt, \"pred_close\": y_pred})\n",
        "    known_closes = np.append(known_closes, y_pred)\n",
        "\n",
        "pred_df = pd.DataFrame(pred_rows)\n",
        "true_df = df_combo.loc[df_combo[\"date\"].isin(pred_df[\"date\"]), [\"date\", \"close\"]].rename(columns={\"close\": \"true_close\"})\n",
        "cmp = pred_df.merge(true_df, on=\"date\", how=\"left\")\n",
        "\n",
        "used_day = cmp.loc[cmp[\"date\"] <= TARGET_DAY, \"date\"].max()\n",
        "\n",
        "pred_target = float(cmp.loc[cmp[\"date\"] == used_day, \"pred_close\"].iloc[0])\n",
        "true_target = float(cmp.loc[cmp[\"date\"] == used_day, \"true_close\"].iloc[0])\n",
        "rel_err = abs(pred_target - true_target) / true_target\n",
        "\n",
        "print(\"Autoregressive prediction\")\n",
        "print(\"cutoff:\", CUTOFF_DAY.date(), \"| last known trading day:\", last_known.date())\n",
        "print(\"requested target:\", TARGET_DAY.date(), \"| used:\", used_day.date())\n",
        "print(\"pred:\", pred_target, \"| true:\", true_target, \"| rel_err:\", float(rel_err))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d0f7c0",
      "metadata": {},
      "source": [
        "### Autoregressive forecast plot\n",
        "Predicted vs true close values over the forecast horizon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plot_autoregressive",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(\n",
        "    cmp,\n",
        "    x=\"date\",\n",
        "    y=[\"true_close\", \"pred_close\"],\n",
        "    title=f\"{TICKER} — Autoregressive forecast (from {last_known.date()} to {used_day.date()})\",\n",
        "    labels={\"value\": \"close\", \"variable\": \"\", \"date\": \"date\"},\n",
        ")\n",
        "fig.update_layout(legend_title_text=\"\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3bbd61",
      "metadata": {},
      "source": [
        "## Critical limitations of linear regression (discussion)\n",
        "\n",
        "- **Linearity constraint:** the model can only represent linear relationships between features and the target.\n",
        "- **Missing exogenous drivers:** price movements are often driven by news, earnings, macro conditions, and sentiment, which are not included here.\n",
        "- **Error propagation in autoregressive mode:** multi-step forecasts can both amplify errors and collapse toward a fixed point once predictions are fed back in, return/volatility features tend toward ~0 and lag/MA features become self-consistent, so the model quickly produces a smooth, near-constant path that drifts away from real-market variability.\n",
        "- **Non-stationarity / concept drift:** patterns from 2015–2023 may not hold in 2026."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
